data:
  corpus:                                 # Pass to dataloader
    # The following depends on corpus
    path: '/data/storage/harry'
    name: 'LibriSpeech'
    train_split: ['LibriSpeech', 'train-clean-360', 'train']
    dev_split: [['LibriSpeech', 'dev-clean', 'dev']]
    bucketing: True
    batch_size: 16

  audio:                                  # Pass to audio transform
    feat_type: 'fbank'
    feat_dim:  80
    apply_cmvn: False
    delta_order: 1                        # 0: do nothing, 1: add delta, 2: add delta and accelerate
    delta_window_size: 2
    frame_length: 25 # ms
    frame_shift: 10 # ms
    ref_level_db: 20
    min_level_db: -100
    preemphasis_coeff: 0.97

  text:
    mode: 'character'                     # 'character'/'word == phone'/'subword'
    vocab_file: 'corpus/librispeech_char.txt'

hparas:                                   # Experiment hyper-parameters
  valid_step: 5000
  max_step: 500000
  tf_start: 1.0
  tf_end: 1.0
  tf_step: 150000
  optimizer: 'Adadelta'
  lr: 1.0
  eps: 0.00000001                          # 1e-8
  lr_scheduler: 'fixed'                    # 'fixed'/'warmup'
  curriculum: 0
  val_mode: 'wer'

model:                                     # Model architecture
  ctc_weight: 0.5                           # Weight for CTC loss
  encoder:
    vgg: 0                                 # 4x reduction on time feature extraction
    vgg_freq: -1
    vgg_low_filt: -1
    module: 'LSTM'                         # 'LSTM'/'GRU'/'Transformer'
    bidirection: True
    dim: [320,320,320,320]
    dropout: [0,0,0,0]
    layer_norm: [False,False,False,False]
    proj: [True,True,True,True]            # Linear projection + Tanh after each rnn layer
    sample_rate: [1,2,1,1]
    sample_style: 'drop'                   # 'drop'/'concat'
  attention: False
  decoder: False
